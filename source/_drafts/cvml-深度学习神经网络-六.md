---
title: 深度学习神经网络(六)
categories:
  - 科研学习 - 计算机视觉与机器学习
tags:
  - 计算机视觉
  - 机器学习
  - 数据聚类
cover: /images/cover/线性分类器.jpg
katex: true
abbrlink: a150702c
---

# 神经网络发展历史

- 1943年，美国心理学家 W.S. McCulloch 和数学家 W.A. Pitts 首次提出神经元的计算模型（简称 M-P 模型）。M-P 模型是对生物神经元的数学建模，为后续神经网络的研究奠定了基础。

    ![](/images/cvml-深度学习神经网络-六/2020-03-16-15-24-01.png)

- 1958年，耶鲁大学 F.Rosenblatt 等人研制出感知器（perceptron），用来完成图像识别任务。被认为是最早的人工神经网络，其参数完全通过对训练样本的学习来决定。

    ![](/images/cvml-深度学习神经网络-六/picture.png)

- 1969年 M.Minsky 和 S.Papert 证明单层 perceptron 网络功能有限，而关于多层神经网络还没有行之有效的训练方法。

- 1986年 Rumelhart, G.E. Hinton 等人提出了 BP 算法，解决了训练多层神经网络的问题

    ![](/images/cvml-深度学习神经网络-六/2020-03-16-15-32-32.png)

- BP 算法存在一些问题，如 gradient diffusion, local minima, over-fitting 等。上述问题导致 BP 算法在深层网络中并不可行，在实际应用中很难得到最优解。

- 卷积神经网络（CNN）是唯一一个能够用 BP 算法训练多个隐层的网络，该网络在手写体文字识别领域与 SVM 不相上下。

    |       | 优点      | 缺点      |
    |--|--|--|
    |SVM    | 用法简单</br>无需大量训练样本| 需要人工抽取有效特征|
    |CNN    | 无需人工提取特征  | 自由度极高，难以使用</br>需要大量训练样本|

- 2006年，G.E. Hinton 的团队提出了一套行之有效的训练深层神经网络的方法。利用该算法的自编码器、深度置信网络等在多个领域得到成功应用，但该成果并未收到足够重视。

















# 更多

参考[科研学习-计算机视觉与机器学习](/categories/科研学习-计算机视觉与机器学习/)